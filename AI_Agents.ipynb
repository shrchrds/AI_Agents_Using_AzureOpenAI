{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --quiet langchain langchain-community langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_version = os.getenv(\"api_version\")\n",
    "deployment = os.getenv(\"DEPLOYMENT_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = AZURE_OPENAI_API_KEY\n",
    "os.environ[\"OPENAI_API_VERSION\"] = api_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    azure_endpoint=endpoint,\n",
    "    api_version=api_version,\n",
    ")\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-9kmlK9nOFkOzO7DSWtdYZMOO2a98i\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"Azure Machine Learning and Azure AI services are both part of Microsoft's suite of cloud-based AI and machine learning tools, but they serve different purposes and target different aspects of the AI lifecycle. Here are the key differences between them:\\n\\n### Azure Machine Learning\\n\\n1. **Purpose**: \\n   - Azure Machine Learning is designed for building, training, and deploying machine learning models. It's a comprehensive service for data scientists, machine learning engineers, and developers.\\n\\n2. **Features**:\\n   - **Model Training**: Supports a variety of frameworks like TensorFlow, PyTorch, and Scikit-learn.\\n   - **Automated ML**: Offers automated machine learning capabilities to automatically build and tune models.\\n   - **MLOps**: Provides tools for deploying, monitoring, and managing models in production, supporting the full machine learning lifecycle.\\n   - **Notebooks**: Integrated Jupyter notebooks for interactive data analysis and model training.\\n   - **Compute**: Scalable compute options including Azure Machine Learning compute clusters and Azure Databricks integration.\\n   - **Data Labeling**: Integrated data labeling services for supervised learning tasks.\\n\\n3. **Target Audience**:\\n   - Primarily data scientists, machine learning engineers, and organizations looking to build custom machine learning models.\\n\\n### Azure AI Services (formerly Cognitive Services)\\n\\n1. **Purpose**:\\n   - Azure AI services are pre-built APIs and tools that provide ready-to-use, high-level AI capabilities. These services allow developers to add AI functionalities to applications without needing deep knowledge of machine learning.\\n\\n2. **Features**:\\n   - **Vision**: Image and video analysis, optical character recognition (OCR), and facial recognition.\\n   - **Speech**: Speech-to-text, text-to-speech, and speech translation.\\n   - **Language**: Text analytics, language understanding (LUIS), and translation services.\\n   - **Decision**: Anomaly detection, content moderation, and personalized recommendations.\\n   - **Search**: Azure Cognitive Search for building sophisticated search experiences.\\n\\n3. **Target Audience**:\\n   - Developers and businesses that want to integrate AI capabilities into their applications quickly and efficiently without the need for custom model development.\\n\\n### Summary of Differences\\n\\n- **Complexity**:\\n  - **Azure Machine Learning**: More complex, offering full control over model creation, training, and deployment.\\n  - **Azure AI Services**: Simplified, providing ready-to-use AI functionalities via APIs.\\n\\n- **Use Cases**:\\n  - **Azure Machine Learning**: Custom machine learning solutions, MLOps, advanced data science projects.\\n  - **Azure AI Services**: Adding specific AI capabilities like vision, speech, language, and search to applications.\\n\\n- **Customization**:\\n  - **Azure Machine Learning**: Highly customizable, suitable for custom model development and optimization.\\n  - **Azure AI Services**: Limited customization, designed for quick integration of predefined AI capabilities.\\n\\n- **Target Users**:\\n  - **Azure Machine Learning**: Data scientists, ML engineers, advanced developers.\\n  - **Azure AI Services**: General developers, businesses looking for quick AI integrations.\\n\\nIn summary, Azure Machine Learning is ideal for those looking to build and manage custom machine learning models, while Azure AI services are perfect for developers who need to quickly add AI functionalities to their applications without extensive machine learning expertise.\",\n",
      "        \"role\": \"assistant\"\n",
      "      },\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1720937558,\n",
      "  \"model\": \"gpt-4o-2024-05-13\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": \"fp_abc28019ad\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 674,\n",
      "    \"prompt_tokens\": 20,\n",
      "    \"total_tokens\": 694\n",
      "  },\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages= [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"What are the differences between Azure Machine Learning and Azure AI services?\"\n",
    "    }],\n",
    "    max_tokens=800,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    stop=None,\n",
    "    stream=False\n",
    ")\n",
    "print(completion.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(model=\"gpt-35-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"you are a helpful assistant. Answer all the question to the best of your ability.\"\n",
    "    ),\n",
    "    MessagesPlaceholder(variable_name = \"messages\"),\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain =  prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "resposne = chain.invoke(\n",
    "    {\n",
    "       \"messages\": [\n",
    "\n",
    "                   HumanMessage(\n",
    "                       content= \"translate this given sentence from english to french: I LOVE AI.\"\n",
    "                   ),\n",
    "                   AIMessage(content= \"J'adore la AI.\"),\n",
    "\n",
    "                   HumanMessage(content= \"what did you just say?\"),\n",
    "       ]    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I said, \"J\\'adore la AI\" which translates to \"I love AI\" in English.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposne.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_chat_history=ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_chat_history.add_user_message(\"translate this given sentence from english to french: I LOVE AI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_chat_history.add_ai_message(\"J'adore la AI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='translate this given sentence from english to french: I LOVE AI.'),\n",
       " AIMessage(content=\"J'adore la AI.\")]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_chat_history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1=\"who is a founder of OpenAI?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_chat_history.add_user_message(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='translate this given sentence from english to french: I LOVE AI.'),\n",
       " AIMessage(content=\"J'adore la AI.\"),\n",
       " HumanMessage(content='who is a founder of OpenAI?')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_chat_history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "resposne=chain.invoke(\n",
    "    {\n",
    "        \"messages\": demo_chat_history.messages\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The co-founders of OpenAI are Elon Musk, Sam Altman, Greg Brockman, Ilya Sutskever, John Schulman, and Wojciech Zaremba.'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposne.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_chat_history.add_ai_message(resposne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "input2=\"what did i ask to you just now?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='translate this given sentence from english to french: I LOVE AI.'),\n",
       " AIMessage(content=\"J'adore la AI.\"),\n",
       " HumanMessage(content='who is a founder of OpenAI?'),\n",
       " AIMessage(content='The co-founders of OpenAI are Elon Musk, Sam Altman, Greg Brockman, Ilya Sutskever, John Schulman, and Wojciech Zaremba.', response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 64, 'total_tokens': 103}, 'model_name': 'gpt-35-turbo', 'system_fingerprint': 'fp_811936bd4f', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-7b402118-d042-4d06-902c-e4dc099fc7fb-0', usage_metadata={'input_tokens': 64, 'output_tokens': 39, 'total_tokens': 103})]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_chat_history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = chain.invoke(\n",
    "    {\n",
    "        \"messages\": demo_chat_history.messages\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The co-founders of OpenAI are Elon Musk, Sam Altman, Greg Brockman, Ilya Sutskever, John Schulman, and Wojciech Zaremba.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain2 = prompt2 | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3 = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt3 | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_chat_history2 = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_message_history = RunnableWithMessageHistory(\n",
    "                              chain,\n",
    "                              lambda session_id: demo_chat_history2,\n",
    "                              input_message_key = \"input\",\n",
    "                              history_message_key =\"chat_history\",\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Je aime la programmation.', response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 45, 'total_tokens': 51}, 'model_name': 'gpt-35-turbo', 'system_fingerprint': 'fp_811936bd4f', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-73b20473-7c31-4597-8e01-692f4f1ad2b5-0', usage_metadata={'input_tokens': 45, 'output_tokens': 6, 'total_tokens': 51})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_message_history.invoke(\n",
    "    {\"input\": \"Translate this sentence from English to French: I love programming.\"},\n",
    "    {\"configurable\": {\"session_id\": \"unused\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You just asked me to translate the sentence \"I love programming\" from English to French.', response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 334, 'total_tokens': 352}, 'model_name': 'gpt-35-turbo', 'system_fingerprint': 'fp_811936bd4f', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-89a84029-b1d3-476a-a751-64216400e32c-0', usage_metadata={'input_tokens': 334, 'output_tokens': 18, 'total_tokens': 352})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_message_history.invoke(\n",
    "    {\"input\": \"What did I just ask you?\"}, {\"configurable\": {\"session_id\": \"unused\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversational Buffer Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use RunnableWithMessageHistory: https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "conversation = ConversationChain(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "print(conversation.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = \"I am pationate about exploring use cases of Large Language models to solve Business problems\"\n",
    "question2 = \"How to analyze business impact of using Large Language Models in Help Desk?\"\n",
    "question3 = \"How to track effort reduction due to use of Large Language Models in Customer Support?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_buff = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory = ConversationBufferMemory()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Hello AI',\n",
       " 'history': '',\n",
       " 'response': 'Hello! How can I assist you today?'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_buff(\"Hello AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(chain,query):\n",
    "    with get_openai_callback() as cb:\n",
    "        result = chain.invoke(query)\n",
    "        print(f\"Total Number of Tokens:  {cb.total_tokens}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Tokens:  289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'I am pationate about exploring use cases of Large Language models to solve Business problems',\n",
       " 'history': \"Human: Hello AI\\nAI: Hello! How can I assist you today?\\nHuman: I am pationate about exploring use cases of Large Language models to solve Business problems\\nAI: That's great to hear! Large language models like GPT-3 have been used in a variety of business applications such as chatbots, content generation, sentiment analysis, and more. They can help businesses automate tasks, improve customer interactions, and gain insights from large amounts of text data. Is there a specific business problem you're interested in exploring with large language models?\",\n",
       " 'response': 'It sounds like you have a strong interest in leveraging large language models for business solutions. There are many potential use cases for these models, such as text summarization, language translation, and even generating code snippets. By utilizing the capabilities of large language models, businesses can streamline processes, enhance communication, and make more informed decisions based on data analysis. If you have a particular business problem in mind, I would be happy to discuss how large language models can be applied to address it.'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tokens(conv_buff, question1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm2 = AzureChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_buff = ConversationChain(\n",
    "    llm=llm2,\n",
    "    memory = ConversationBufferMemory()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'I am pationate about exploring use cases of Large Language models to solve Business problems',\n",
       " 'history': '',\n",
       " 'response': \"That's fantastic! Large Language Models (LLMs) like GPT-3 have a wide range of applications in the business world. Here are a few areas where they can be particularly effective:\\n\\n1. **Customer Support**: LLMs can power chatbots and virtual assistants to handle customer inquiries, provide information, and even troubleshoot common problems. This not only improves customer satisfaction but also reduces the workload on human support agents.\\n\\n2. **Content Creation**: Whether it's drafting emails, writing blog posts, or generating marketing copy, LLMs can help create high-quality content quickly. This can be especially useful for maintaining a consistent online presence and engaging with customers through various channels.\\n\\n3. **Data Analysis and Reporting**: LLMs can analyze large datasets and generate reports in natural language, making complex data more accessible and understandable for business decision-makers.\\n\\n4. **Personalization**: By analyzing customer data, LLMs can help create personalized experiences for users, whether it's through tailored product recommendations, customized marketing messages, or personalized onboarding processes.\\n\\n5. **Market Research**: LLMs can assist in gathering and summarizing information about market trends, competitor activities, and customer preferences, providing valuable insights for strategic planning.\\n\\n6. **Translation and Localization**: For businesses operating globally, LLMs can provide translation services to communicate effectively with customers and partners in different languages.\\n\\n7. **Fraud Detection and Risk Management**: By analyzing transaction data and identifying unusual patterns, LLMs can help detect fraudulent activities and assess risks, protecting businesses from potential losses.\\n\\n8. **Internal Knowledge Management**: LLMs can assist in organizing and retrieving information within a company, making it easier for employees to find the resources they need, whether it's policy documents, technical manuals, or historical data.\\n\\nIf you have a specific business problem in mind, I'd be happy to dive deeper into how LLMs can be applied to address it!\"}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_buff(question1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
